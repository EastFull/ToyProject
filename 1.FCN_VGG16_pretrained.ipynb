{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FCN_VGG16_pretrained.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YjJZYNTSIJcY","colab_type":"code","outputId":"3e319663-ff91-47d0-a1bf-9f184274c6ec","executionInfo":{"status":"ok","timestamp":1575942924627,"user_tz":-540,"elapsed":48902,"user":{"displayName":"‍이동찬[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"09370646276717963240"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["!pip install -q tensorflow-gpu==2.0.0-rc1"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 380.5MB 46kB/s \n","\u001b[K     |████████████████████████████████| 501kB 43.2MB/s \n","\u001b[K     |████████████████████████████████| 4.3MB 55.0MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JOjZavL41uy_","colab_type":"code","colab":{}},"source":["# Connect Google Drive\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","%cd ./gdrive/\"My Drive\"/\"Colab Notebooks\"/\"Fully Convolutional Network for Semantic segmentation\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKcfa5aT1w1N","colab_type":"code","colab":{}},"source":["import cv2\n","import numpy as np\n","import random\n","import csv\n","import time\n","import os\n","import glob\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, ReLU, Conv2DTranspose\n","\n","IMG_SIZE = 384\n","num_classes = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWovgWiq10t-","colab_type":"code","colab":{}},"source":["# get data from directory\n","def prepare_data(dataset_dir):\n","    train_input_names=[]\n","    train_output_names=[]\n","    test_input_names=[]\n","    test_output_names=[]\n","\n","    train_input_names = glob.glob(dataset_dir + \"/\" + \"train/*\")\n","    train_output_names = glob.glob(dataset_dir + \"/\" + \"train_labels/*\")\n","    test_input_names = glob.glob(dataset_dir + \"/\" + \"test/*\")\n","    test_output_names = glob.glob(dataset_dir + \"/\" + \"test_labels/*\")\n","    \n","    train_input_names.sort(), train_output_names.sort()\n","    test_input_names.sort(), test_output_names.sort()\n","    \n","    return train_input_names, train_output_names, test_input_names, test_output_names\n","\n","def load_image(path):\n","    image = cv2.cvtColor(cv2.imread(path,-1), cv2.COLOR_BGR2RGB)\n","    return image\n","\n","def get_label_info(csv_path):\n","    \"\"\"\n","    Retrieve the class names and label values for the selected dataset.\n","    Must be in CSV format!\n","    # Arguments\n","        csv_path: The file path of the class dictionairy\n","        \n","    # Returns\n","        Two lists: one for the class names and the other for the label values\n","    \"\"\"\n","    class_names = []\n","    label_values = []\n","    with open(csv_path, 'r') as csvfile:\n","        file_reader = csv.reader(csvfile, delimiter=',')\n","        header = next(file_reader)\n","        for row in file_reader:\n","            class_names.append(row[0])\n","            label_values.append([int(row[1]), int(row[2]), int(row[3])])\n","    return class_names, label_values\n","\n","def one_hot_it(label, label_values):\n","    \"\"\"\n","    Convert a segmentation image label array to one-hot format\n","    by replacing each pixel value with a vector of length num_classes\n","    # Arguments\n","        label: The 2D array segmentation image label\n","        label_values\n","        \n","    # Returns\n","        A 2D array with the same width and hieght as the input, but\n","        with a depth size of num_classes\n","    \"\"\"\n","    semantic_map = []\n","    for colour in label_values:\n","        # colour_map = np.full((label.shape[0], label.shape[1], label.shape[2]), colour, dtype=int)\n","        equality = np.equal(label, colour)\n","        class_map = np.all(equality, axis = -1)\n","        semantic_map.append(class_map)\n","    semantic_map = np.stack(semantic_map, axis=-1)\n","\n","    return semantic_map\n","\n","def reverse_one_hot(image):\n","    \"\"\"\n","    Transform a 2D array in one-hot format (depth is num_classes),\n","    to a 2D array with only 1 channel, where each pixel value is\n","    the classified class key.\n","    # Arguments\n","        image: The one-hot format image \n","        \n","    # Returns\n","        A 2D array with the same width and hieght as the input, but\n","        with a depth size of 1, where each pixel value is the classified \n","        class key.\n","    \"\"\"\n","    x = np.argmax(image, axis = -1)\n","    return x\n","\n","def colour_code_segmentation(image, label_values):\n","    \"\"\"\n","    Given a 1-channel array of class keys, colour code the segmentation results.\n","    # Arguments\n","        image: single channel array where each value represents the class key.\n","        label_values\n","        \n","    # Returns\n","        Colour coded image for segmentation visualization\n","    \"\"\"\n","    \n","    colour_codes = np.array(label_values)\n","    x = colour_codes[image.astype(int)]\n","\n","    return x\n","\n","# Randomly crop the image to a specific size. For data augmentation\n","def random_crop(image, label, crop_height, crop_width):\n","    if (image.shape[0] != label.shape[0]) or (image.shape[1] != label.shape[1]):\n","        raise Exception('Image and label must have the same dimensions!')\n","        \n","    if (crop_width <= image.shape[1]) and (crop_height <= image.shape[0]):\n","        x = random.randint(0, image.shape[1]-crop_width)\n","        y = random.randint(0, image.shape[0]-crop_height)\n","        \n","        if len(label.shape) == 3:\n","            return image[y:y+crop_height, x:x+crop_width, :], label[y:y+crop_height, x:x+crop_width, :]\n","        else:\n","            return image[y:y+crop_height, x:x+crop_width, :], label[y:y+crop_height, x:x+crop_width]\n","    else:\n","        raise Exception('Crop shape (%d, %d) exceeds image dimensions (%d, %d)!' % (crop_height, crop_width, image.shape[0], image.shape[1]))\n","\n","# data augmentation\n","def data_augmentation(input_image, output_image):\n","    h_flip = True # to randomly flip the image horizontally for data augmentation.\n","    v_flip = True # to randomly flip the image vertically for data augmentation.\n","    brightness = 0.1 # to randomly change the image brightness for data augmentation. Specifies the max bightness change as a factor between 0.0 and 1.0. For example, 0.1 represents a max brightness change of 10%% (+-).\n","    rotation = 90 # to randomly rotate the image for data augmentation. Specifies the max rotation angle in degrees.\n","    crop_height = IMG_SIZE # Height of cropped input image to network\n","    crop_width = IMG_SIZE # Width  of cropped input image to network\n","    \n","    # Data augmentation\n","    input_image, output_image = random_crop(input_image, output_image, crop_height, crop_width)\n","\n","    if h_flip and random.randint(0,1):\n","        input_image = cv2.flip(input_image, 1)\n","        output_image = cv2.flip(output_image, 1)\n","    if v_flip and random.randint(0,1):\n","        input_image = cv2.flip(input_image, 0)\n","        output_image = cv2.flip(output_image, 0)\n","    if brightness:\n","        factor = 1.0 + random.uniform(-1.0*brightness, brightness)\n","        table = np.array([((i / 255.0) * factor) * 255 for i in np.arange(0, 256)]).astype(np.uint8)\n","        input_image = cv2.LUT(input_image, table)\n","    if rotation:\n","        angle = random.uniform(-1*rotation, rotation)\n","    if rotation:\n","        M = cv2.getRotationMatrix2D((input_image.shape[1]//2, input_image.shape[0]//2), angle, 1.0)\n","        input_image = cv2.warpAffine(input_image, M, (input_image.shape[1], input_image.shape[0]), flags=cv2.INTER_NEAREST)\n","        output_image = cv2.warpAffine(output_image, M, (output_image.shape[1], output_image.shape[0]), flags=cv2.INTER_NEAREST)\n","\n","    return input_image, output_image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Tm7NzVHDC0x","colab_type":"code","colab":{}},"source":["def compute_global_accuracy(pred, label):\n","    total = len(label)\n","    count = 0.0\n","    for i in range(total):\n","        if pred[i] == label[i]:\n","            count = count + 1.0\n","    return float(count) / float(total)\n","\n","# Compute the class-specific segmentation accuracy\n","def compute_class_accuracies(pred, label, num_classes):\n","    total = []\n","    for val in range(num_classes):\n","        total.append((label == val).sum())\n","\n","    count = [0.0] * num_classes\n","    for i in range(len(label)):\n","        if pred[i] == label[i]:\n","            count[int(pred[i])] = count[int(pred[i])] + 1.0\n","\n","    # If there are no pixels from a certain class in the GT, \n","    # it returns NAN because of divide by zero\n","    # Replace the nans with a 1.0.\n","    accuracies = []\n","    for i in range(len(total)):\n","        if total[i] == 0:\n","            accuracies.append(1.0)\n","        else:\n","            accuracies.append(count[i] / total[i])\n","\n","    return accuracies\n","\n","\n","def compute_mean_iou(pred, label):\n","\n","    unique_labels = np.unique(label)\n","    num_unique_labels = len(unique_labels);\n","\n","    I = np.zeros(num_unique_labels)\n","    U = np.zeros(num_unique_labels)\n","\n","    for index, val in enumerate(unique_labels):\n","        pred_i = pred == val\n","        label_i = label == val\n","\n","        I[index] = float(np.sum(np.logical_and(label_i, pred_i)))\n","        U[index] = float(np.sum(np.logical_or(label_i, pred_i)))\n","\n","\n","    mean_iou = np.mean(I / U)\n","    return mean_iou\n","\n","\n","def evaluate_segmentation(pred, label, num_classes, score_averaging=\"weighted\"):\n","    flat_pred = pred.flatten()\n","    flat_label = label.flatten()\n","\n","    global_accuracy = compute_global_accuracy(flat_pred, flat_label)\n","    class_accuracies = compute_class_accuracies(flat_pred, flat_label, num_classes)\n","\n","    iou = compute_mean_iou(flat_pred, flat_label)\n","\n","    return global_accuracy, class_accuracies, iou\n","\n","# Takes an absolute file path and returns the name of the file without th extension\n","def filepath_to_name(full_name):\n","    file_name = os.path.basename(full_name)\n","    file_name = os.path.splitext(file_name)[0]\n","    return file_name"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2y7xH1lOJVzN","colab_type":"code","colab":{}},"source":["# add fully convolutional layer\n","class Conv1BatchNorm(tf.keras.layers.Layer):\n","\n","    def __init__(self, kernel_size):\n","        super(Conv1BatchNorm, self).__init__()\n","        self.conv = Conv2D(4096, kernel_size)\n","        self.batchnorm = BatchNormalization()\n","        self.relu = ReLU()\n","\n","    def call(self, x):\n","        x = self.conv(x)\n","        x = self.batchnorm(x)\n","        return self.relu(x)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEXRMPLXIVis","colab_type":"code","colab":{}},"source":["IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","\n","base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE, \n","                                         include_top=False,\n","                                         weights='imagenet')\n","\n","base_model.trainable = False\n","base_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HW4ZU-ROJCX0","colab_type":"code","colab":{}},"source":["# add fully convolutional layer\n","class FCN_VGG16(tf.keras.Model):\n","\n","    def __init__(self, num_classes=21, base_model=None):\n","        super(FCN_VGG16, self).__init__()\n","        if base_model != None:\n","            self.base = base_model\n","        self.conv6 = Conv1BatchNorm(1)\n","        self.conv7 = Conv1BatchNorm(1)\n","      \n","        self.score_fc = Conv2D(num_classes, 1, activation='relu')\n","        \n","        self.score_pool4 = Conv2D(num_classes, 1, padding='same', activation='relu')\n","        self.score_pool3 = Conv2D(num_classes, 1, activation='relu')\n","\n","        self.upsampling1 = Conv2DTranspose(num_classes, 4, 2, padding='same')\n","        self.upsampling2 = Conv2DTranspose(num_classes, 4, 2, padding='same')\n","        \n","        self.upsample8s = Conv2DTranspose(num_classes, 16, 8, padding='same')\n","\n","    def shadow_model(self, input_content, start_index, end_index):\n","        x = input_content\n","        for i in range(start_index, end_index + 1):\n","            x = self.base.layers[i](x)\n","        return x\n","\n","    def call(self, x):\n","        ##########################pre trained###########################\n","        input_image = x\n","        x = self.base(x)\n","        pool3 = self.shadow_model(input_image, 1, 10)\n","        pool4 = self.shadow_model(pool3, 11, 14)\n","        ################################################################\n","        x = self.conv6(x)\n","        x = self.conv7(x)\n","        x = self.score_fc(x)\n","\n","        fusion1 = tf.add(self.upsampling1(x), self.score_pool4(pool4))\n","        fusion2 = tf.add(self.upsampling2(fusion1), self.score_pool3(pool3))\n","\n","        return self.upsample8s(fusion2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nV2UGhnq2MJX","colab_type":"code","colab":{}},"source":["dnn_model = FCN_VGG16(num_classes, base_model)\n","\n","loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n","optimizer = tf.keras.optimizers.RMSprop()\n","\n","checkpoint_directory = \"./checkpoints\"\n","checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpts1\")\n","\n","ckpt = tf.train.Checkpoint(optimizer=optimizer, net=dnn_model)\n","manager = tf.train.CheckpointManager(ckpt, './checkpoints/ckpts1', max_to_keep=50)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n","\n","def train_step(images, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = dnn_model(images)\n","        loss = loss_object(labels, predictions)\n","\n","    gradients = tape.gradient(loss, dnn_model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, dnn_model.trainable_variables))\n","    \n","    train_loss(loss)\n","    train_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQl52nGT2RlO","colab_type":"code","colab":{}},"source":["class_names_list, label_values = get_label_info(\"CamVid/class_dict.csv\")\n","class_names_string = \"\"\n","with tf.device('/cpu:0'):\n","    for class_name in class_names_list:\n","        if not class_name == class_names_list[-1]:\n","            class_names_string = class_names_string + class_name + \", \"\n","        else:\n","            class_names_string = class_names_string + class_name\n","num_classes = len(label_values)\n","\n","print(\"Loading the data ...\", end=' ')\n","train_input_names, train_output_names, test_input_names, test_output_names = prepare_data(\"CamVid\")\n","print(\"Complete!!\")\n","\n","avg_loss_per_epoch = []\n","avg_scores_per_epoch = []\n","avg_iou_per_epoch = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ts1TOkPuDLAf","colab_type":"code","colab":{}},"source":["test_indices = []\n","num_tests = min(20, len(test_input_names))\n","\n","\n","random.seed(16)\n","test_indices=random.sample(range(0,len(test_input_names)),num_tests)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nxqzyTi92bB9","colab_type":"code","colab":{}},"source":["batch_size = 16\n","stat_period = 1\n","\n","for epoch in range(50):\n","    print(\"epoch: \", epoch + 1)\n","    start_time = time.time()\n","\n","    id_list = np.random.permutation(len(train_input_names))\n","\n","    num_iters = int(np.floor(len(id_list) / batch_size))\n","    for i in range(num_iters):\n","        input_image_batch = []\n","        output_image_batch = []\n","\n","        # Collect a batch of images\n","        for j in range(batch_size):\n","            index = i * batch_size + j\n","            id = id_list[index]\n","            input_image = load_image(train_input_names[id])\n","            output_image = load_image(train_output_names[id])\n","\n","            with tf.device('/cpu:0'):\n","                input_image, output_image = data_augmentation(input_image, output_image)\n","\n","                # Prep the data. Make sure the labels are in one-hot format\n","                input_image = np.float32(input_image) / 255.0\n","                output_image = np.float32(one_hot_it(label=output_image, label_values=label_values))\n","\n","                input_image_batch.append(np.expand_dims(input_image, axis=0))\n","                output_image_batch.append(np.expand_dims(output_image, axis=0))\n","\n","        if batch_size == 1:\n","            input_image_batch = input_image_batch[0]\n","            output_image_batch = output_image_batch[0]\n","        else:\n","            input_image_batch = np.squeeze(np.stack(input_image_batch, axis=1))\n","            output_image_batch = np.squeeze(np.stack(output_image_batch, axis=1))\n","        train_step(input_image_batch, output_image_batch)\n","            \n","    end_time = time.time()\n","     \n","    if epoch % stat_period is 0:\n","        template = \"\\t{} (sec/epoch), Epoch {}, Loss: {}, Accuracy: {} %\"\n","        print(template.format((end_time - start_time) / stat_period,\n","                              epoch + 1,\n","                              train_loss.result(),\n","                              train_accuracy.result() * 100))\n","        avg_loss_per_epoch.append(train_loss.result())\n","        \n","        save_path = manager.save()\n","        print(\"\\tSaved checkpoint for epoch {}: {}\".format(epoch + 1, save_path))\n","\n","        train_loss.reset_states()\n","        train_accuracy.reset_states()\n","      \n","        print(\"\\tPerforming test\")\n","\n","        target=open(\"%s/%04dtest_scores.csv\"%(\"checkpoints_test\",epoch),'w')\n","        target.write(\"test_name, avg_accuracy, mean iou, %s\\n\" % (class_names_string))\n","\n","        scores_list = []\n","        class_scores_list = []\n","        iou_list = []\n","\n","        for ind in test_indices:\n","            input_image = np.expand_dims(np.float32(load_image(test_input_names[ind])[:IMG_SIZE, :IMG_SIZE]),axis=0)/255.0\n","            gt = load_image(test_output_names[ind])[:IMG_SIZE, :IMG_SIZE]\n","            gt = reverse_one_hot(one_hot_it(gt, label_values))\n","\n","            output_image = dnn_model(input_image)\n","\n","            output_image = np.array(output_image[0,:,:,:])\n","            output_image = reverse_one_hot(output_image)\n","            out_vis_image = colour_code_segmentation(output_image, label_values)\n","\n","            accuracy, class_accuracies, iou = evaluate_segmentation(pred=output_image, label=gt, num_classes=num_classes)\n","\n","            file_name = filepath_to_name(test_input_names[ind])\n","            target.write(\"%s, %f, %f\"%(file_name, accuracy, iou))\n","            for item in class_accuracies:\n","                target.write(\", %f\"%(item))\n","            target.write(\"\\n\")\n","\n","            scores_list.append(accuracy)\n","            class_scores_list.append(class_accuracies)\n","            iou_list.append(iou)\n","\n","            gt = colour_code_segmentation(gt, label_values)\n","\n","            file_name = os.path.basename(test_input_names[ind])\n","            file_name = os.path.splitext(file_name)[0]\n","            cv2.imwrite(\"%s/%04d%s_pred.png\"%(\"checkpoints_test\", epoch, file_name),cv2.cvtColor(np.uint8(out_vis_image), cv2.COLOR_RGB2BGR))\n","            cv2.imwrite(\"%s/%04d%s_gt.png\"%(\"checkpoints_test\", epoch, file_name),cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2BGR))\n","        target.close()\n","\n","        avg_score = np.mean(scores_list)\n","        class_avg_scores = np.mean(class_scores_list, axis=0)\n","        avg_scores_per_epoch.append(avg_score)\n","        avg_iou = np.mean(iou_list)\n","\n","        print(\"\\nAverage test accuracy for epoch # %04d = %f\"% (epoch, avg_score))\n","        print(\"Average per class test accuracies for epoch # %04d:\"% (epoch))\n","        for index, item in enumerate(class_avg_scores):\n","            print(\"%s = %f\" % (class_names_list[index], item))\n","        print(\"Test IoU score = \", avg_iou)"],"execution_count":0,"outputs":[]}]}